{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\features2d\\src\\sift.dispatch.cpp:477: error: (-5:Bad argument) image is empty or has incorrect depth (!=CV_8U) in function 'cv::SIFT_Impl::detectAndCompute'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-0f5e5c489b28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0msift\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSIFT_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# find the keypoints and descriptors with SIFT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mkp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdes1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mresult1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdes1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mkp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdes2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\features2d\\src\\sift.dispatch.cpp:477: error: (-5:Bad argument) image is empty or has incorrect depth (!=CV_8U) in function 'cv::SIFT_Impl::detectAndCompute'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "MIN_MATCH_COUNT = 10\n",
    "def make_dict(kp, des):\n",
    "    loc = []\n",
    "    for i in range(len(kp)):\n",
    "        px = kp1[i].pt[0]\n",
    "        py = kp1[i].pt[1]\n",
    "        loc.append([px, py])\n",
    "    dict = {\"descriptors\": des,\n",
    "            \"locations\": loc}\n",
    "    return dict\n",
    "\n",
    "# img1 = cv.imread('IMG_20210602_174916.jpg',0)          # queryImage\n",
    "# img2 = cv.imread('IMG_20210602_174952.jpg',0) # trainImage\n",
    "img1 = cv.imread(\"image1.jpg\", 0)\n",
    "img1 = cv.imread(\"image2.jpg\", 0)\n",
    "# Initiate SIFT detector\n",
    "sift = cv.SIFT_create()\n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "result1 = make_dict(kp1, des1)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "result2 = make_dict(kp2, des2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.spatial import cKDTree\n",
    "from skimage.feature import plot_matches\n",
    "from skimage.measure import ransac\n",
    "from skimage.transform import AffineTransform\n",
    "# result1 and result2 is dictionary of locations and descriptors\n",
    "def match_images(image1, image2, result1, result2):\n",
    "    distance_threshold = 0.8\n",
    "\n",
    "    # Read features.\n",
    "    num_features_1 = len(result1['locations'])\n",
    "    print(\"Loaded image 1's %d features\" % num_features_1)\n",
    "\n",
    "    num_features_2 = len(result2['locations'])\n",
    "    print(\"Loaded image 2's %d features\" % num_features_2)\n",
    "\n",
    "#     # Find nearest-neighbor matches using a KD tree.\n",
    "#     d1_tree = cKDTree(result1['descriptors'])\n",
    "#     _, indices = d1_tree.query(\n",
    "#       result2['descriptors'],\n",
    "#       distance_upper_bound=distance_threshold)\n",
    "\n",
    "#     # Select feature locations for putative matches.\n",
    "#     locations_2_to_use = np.array([result2['locations'][i,] for i in range(num_features_2) if indices[i] != num_features_1])\n",
    "#     locations_1_to_use = np.array([\n",
    "#       result1['locations'][indices[i],]\n",
    "#       for i in range(num_features_2)\n",
    "#       if indices[i] != num_features_1\n",
    "#     ])\n",
    "    locations_2_to_use = \n",
    "\n",
    "    # Perform geometric verification using RANSAC.\n",
    "    try:\n",
    "      _, inliers = ransac(\n",
    "          (locations_2_use_db, locations_2_use_query), # source and destination coordinates\n",
    "          AffineTransform,\n",
    "          min_samples=2,\n",
    "          residual_threshold=20,\n",
    "          max_trials=1000\n",
    "          )\n",
    "    except:\n",
    "        print('NO inliers found - error')\n",
    "        return -1\n",
    "\n",
    "    print('Found %d inliers' % sum(inliers))\n",
    "\n",
    "    # Visualize correspondences.\n",
    "    _, ax = plt.subplots()\n",
    "    inlier_idxs = np.nonzero(inliers)[0]\n",
    "    plot_matches(\n",
    "      ax,\n",
    "      image1,\n",
    "      image2,\n",
    "      locations_1_to_use,\n",
    "      locations_2_to_use,\n",
    "      np.column_stack((inlier_idxs, inlier_idxs)),\n",
    "      matches_color='b')\n",
    "    ax.axis('off')\n",
    "    ax.set_title('INLIERS AMONG THE IMAGES')\n",
    "    return sum(inliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded image 1's 55023 features\n",
      "Loaded image 2's 13446 features\n",
      "NO inliers found - error\n",
      "no of inliers: -1\n"
     ]
    }
   ],
   "source": [
    "inliers = match_images(img1, img2, result1, result2)\n",
    "print(\"no of inliers: \" + str(inliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
